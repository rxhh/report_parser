{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, LLMConfig, CacheMode\n",
    "from crawl4ai.extraction_strategy import LLMExtractionStrategy\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from pydantic import BaseModel, Field\n",
    "import PyPDF2\n",
    "\n",
    "from secret import openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 'volkswagen'\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root_path = f\"data\\\\{id}\"\n",
    "Path(root_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annual Report DiscoverIdentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'{root_path}\\\\links.csv', index_col=0).to_dict('records')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#special_instructions = \"This company often names its annual reports like reference document or universal registration document. Prefer these over files that are named like annual report.\"\n",
    "#special_instructions = \"In case of duplicates, prefer GAAP adjusted.\"\n",
    "special_instructions = config['annual_reports']['special_instructions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are a utility which picks out the relevant annual reports from a list of URLs.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Get the annual reports from a list of candidate PDF URLs. There must be only one\n",
    "annual report per year. Are are looking for the one with financial statements.\n",
    "\n",
    "Make sure the year is correct. If a date is present in a URL or filename, it\n",
    "might be an upload date. To resolve this, note that the annual report is always\n",
    "uploaded after the year its for.\n",
    "\n",
    "Sort the output by year descending.\n",
    "\n",
    "If there are missing years between the newest and oldest year, there's a high\n",
    "likelihood that data isn't missing. Try to ensure those gaps are filled.\n",
    "\n",
    "Special instructions: {special_instructions}\n",
    "Dataset: {json.dumps(data)}\n",
    "\"\"\"\n",
    "\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"annual_reports\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"year\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The fiscal year of the report.\"\n",
    "                    },\n",
    "                    \"filename\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of the PDF file.\"\n",
    "                    },\n",
    "                    \"url\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The URL linking to the annual report PDF.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"year\", \"filename\", \"url\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"annual_reports\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o3-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"annual_report\",\n",
    "            \"schema\": schema,\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_reports = pd.DataFrame(json.loads(response.output_text)['annual_reports']).set_index('year')\n",
    "annual_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspicious_years = []\n",
    "for year in range(1980, 2025):\n",
    "    if (str(year) in json.dumps(data)) and (not year in annual_reports.index.values):\n",
    "        suspicious_years.append(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(suspicious_years) > 0:\n",
    "    print(f\"Warning: years found in URLs without annual reports: {suspicious_years}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "for y, row in annual_reports.iterrows():\n",
    "    report_path = f\"{root_path}\\\\{y}\"\n",
    "    Path(report_path).mkdir(parents=True, exist_ok=True)\n",
    "    urllib.request.urlretrieve(row['url'], report_path+f\"\\\\{row['filename']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_reports = pd.read_csv(f\"{root_path}\\\\pdfs.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2018\n",
    "report_path = f\"{root_path}\\\\{y}\"\n",
    "report_name = annual_reports.loc[y]['filename']\n",
    "pdf_path = f\"{report_path}\\\\{report_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesize = os.path.getsize(pdf_path)/1024**2\n",
    "with open(pdf_path, \"rb\") as infile:\n",
    "    reader = PyPDF2.PdfReader(infile)\n",
    "    num_pages = len(reader.pages)\n",
    "if filesize > 32 or num_pages > 100:\n",
    "    print(\"File too large for a single request. Use split method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "    file=open(pdf_path, \"rb\"),\n",
    "    purpose=\"user_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_instructions = config['report_parser']['special_instructions']\n",
    "\n",
    "instruction = f\"\"\"\n",
    "\n",
    "From the given annual report, extract the balance sheet, income statement, and \n",
    "cash flow statement data for the current year. The current year is {y}.\n",
    "\n",
    "Your response should simply be a JSON dictionary, ready to load into json.loads.\n",
    "The top level dict keys must be balance_sheet, income_statement, and\n",
    "cash_flow_statement. The values for these keys is another dict, where the items\n",
    "are the relevant data you find. Do not nest another dictionary beyond this\n",
    "level. Make sure there are no duplicate keys. I would like dict keys in\n",
    "lowercase_with_underscores.\n",
    "\n",
    "Special instructions: {special_instructions}\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "    model=\"o1\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_file\",\n",
    "                    \"file_id\": file.id,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": instruction,\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = json.loads(response.output_text)\n",
    "final_dict['year'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict['year'] = y\n",
    "with open(f\"{report_path}\\\\output.json\", 'w') as f:\n",
    "    json.dump(final_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Large PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet_pages = []\n",
    "income_statement_pages = []\n",
    "cash_flow_statement_pages = []\n",
    "\n",
    "with open(pdf_path, \"rb\") as infile:\n",
    "    reader = PyPDF2.PdfReader(infile)\n",
    "    num_pages = len(reader.pages)\n",
    "    \n",
    "    for i in range(num_pages):\n",
    "        page = reader.pages[i]\n",
    "        text = page.extract_text()\n",
    "        if text and 'balance sheet' in text.lower():\n",
    "            for j in range(i, min(i + 3, num_pages)):\n",
    "                if j not in balance_sheet_pages:\n",
    "                    balance_sheet_pages.append(j)\n",
    "        if text and 'income statement' in text.lower():\n",
    "            for j in range(i, min(i + 3, num_pages)):\n",
    "                if j not in income_statement_pages:\n",
    "                    income_statement_pages.append(j)\n",
    "        if text and 'cash flow statement' in text.lower():\n",
    "            for j in range(i, min(i + 3, num_pages)):\n",
    "                if j not in income_statement_pages:\n",
    "                    cash_flow_statement_pages.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reduced_pdf(input_pdf_path, output_pdf_path, page_numbers):\n",
    "    \"\"\"\n",
    "    Create a reduced PDF from the input_pdf_path containing only the pages listed in page_numbers.\n",
    "    \n",
    "    Parameters:\n",
    "        input_pdf_path (str): Path to the original PDF.\n",
    "        output_pdf_path (str): Path where the reduced PDF will be saved.\n",
    "        page_numbers (list): A list of page numbers (0-indexed) to include in the new PDF.\n",
    "    \"\"\"\n",
    "    with open(input_pdf_path, \"rb\") as infile:\n",
    "        reader = PyPDF2.PdfReader(infile)\n",
    "        writer = PyPDF2.PdfWriter()\n",
    "        \n",
    "        # Iterate through the list of page numbers\n",
    "        for page_num in page_numbers:\n",
    "            # Check if the page number is within the range of available pages\n",
    "            if page_num < len(reader.pages):\n",
    "                writer.add_page(reader.pages[page_num])\n",
    "            else:\n",
    "                print(f\"Page {page_num + 1} is out of range. Skipping.\")\n",
    "        \n",
    "        # Save the reduced PDF\n",
    "        with open(output_pdf_path, \"wb\") as outfile:\n",
    "            writer.write(outfile)\n",
    "        print(f\"Reduced PDF saved as: {output_pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet_pdf = f\"{report_path}\\\\_balance_sheet_{report_name}\"\n",
    "income_statement_pdf = f\"{report_path}\\\\_income_statement_{report_name}\"\n",
    "cash_flow_statement_pdf = f\"{report_path}\\\\_cash_flow_statement_{report_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_reduced_pdf(pdf_path, balance_sheet_pdf, balance_sheet_pages)\n",
    "save_reduced_pdf(pdf_path, income_statement_pdf, income_statement_pages)\n",
    "save_reduced_pdf(pdf_path, cash_flow_statement_pdf, cash_flow_statement_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet_file = client.files.create(\n",
    "    file=open(balance_sheet_pdf, \"rb\"),\n",
    "    purpose=\"user_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = f\"\"\"\n",
    "From the given annual report, extract the balance sheet data for the current\n",
    "year. The current year is {y}.\n",
    "\n",
    "Your response should simply be a JSON dictionary, ready to load into json.loads.\n",
    "Dict items are the relevant data you find. Make sure there are no duplicate\n",
    "keys. Do not give a nested dictionary. I would like dict keys in\n",
    "lowercase_with_underscores.\n",
    "\n",
    "Special instructions: {special_instructions}\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "    model=\"o1\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_file\",\n",
    "                    \"file_id\": balance_sheet_file.id,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": instruction,\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "balance_sheet_dict = json.loads(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_statement_file = client.files.create(\n",
    "    file=open(income_statement_pdf, \"rb\"),\n",
    "    purpose=\"user_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = f\"\"\"\n",
    "From the given annual report, extract the income statement data for the current\n",
    "year. The current year is {y}.\n",
    "\n",
    "Your response should simply be a JSON dictionary, ready to load into json.loads.\n",
    "Dict items are the relevant data you find. Make sure there are no duplicate\n",
    "keys. Do not give a nested dictionary. I would like dict keys in\n",
    "lowercase_with_underscores.\n",
    "\n",
    "Special instructions: {special_instructions}\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "    model=\"o1\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_file\",\n",
    "                    \"file_id\": income_statement_file.id,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": instruction,\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "income_statement_dict = json.loads(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_statement_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_flow_statement_file = client.files.create(\n",
    "    file=open(cash_flow_statement_pdf, \"rb\"),\n",
    "    purpose=\"user_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = f\"\"\"\n",
    "From the given annual report, extract the cash flow statement data for the\n",
    "current year. The current year is {y}.\n",
    "\n",
    "Your response should simply be a JSON dictionary, ready to load into json.loads.\n",
    "Dict items are the relevant data you find. Make sure there are no duplicate\n",
    "keys. Do not give a nested dictionary. I would like dict keys in\n",
    "lowercase_with_underscores.\n",
    "\n",
    "Special instructions: {special_instructions}\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "    model=\"o1\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_file\",\n",
    "                    \"file_id\": cash_flow_statement_file.id,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": instruction,\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "cash_flow_statement_dict = json.loads(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_flow_statement_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {\n",
    "    'year': y,\n",
    "    'balance_sheet': balance_sheet_dict,\n",
    "    'income_statement': income_statement_dict,\n",
    "    'cash_flow_statement': cash_flow_statement_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{report_path}\\\\output.json\", 'w') as f:\n",
    "    json.dump(final_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet = []\n",
    "income_statement = []\n",
    "cash_flow_statement = []\n",
    "for y in annual_reports.index:\n",
    "    output_file = f\"{root_path}\\\\{y}\\\\output.json\"\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file) as f:\n",
    "            statement = json.load(f)\n",
    "\n",
    "            statement['balance_sheet'].update({'year':y})\n",
    "            balance_sheet.append(statement['balance_sheet'])\n",
    "\n",
    "            statement['income_statement'].update({'year':y})\n",
    "            income_statement.append(statement['income_statement'])\n",
    "\n",
    "            statement['cash_flow_statement'].update({'year':y})\n",
    "            cash_flow_statement.append(statement['cash_flow_statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = f\"\"\"\n",
    "Consolidate the given data.\n",
    "\n",
    "Each item in the given list is a balance sheet for a given year.\n",
    "\n",
    "The keys need to be consolidated across the years.\n",
    "\n",
    "You may leave some keys as None if there is no matching data for a given year.\n",
    "However, try your best to leave as little data gaps as possible. If there is a\n",
    "reported figure for a given year, it is likely in all years, or subsequent\n",
    "years. For example, \"assets\" may change to \"total_assets\", but these should be\n",
    "merged. There should be no nesting of dictionaries; the data for a given year\n",
    "should be numbers.\n",
    "\n",
    "Use your knowledge about the common items occurring in a balance sheet.\n",
    "\n",
    "Your output should be json.loads ready.\n",
    "\n",
    "Special instructions:\n",
    "{special_instructions}\n",
    "\n",
    "Data:\n",
    "{balance_sheet}\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "    model=\"o3-mini\",\n",
    "    input=instruction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(json.loads(response.output_text)).set_index('year').to_csv(f\"{root_path}\\\\balance_sheet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = f\"\"\"\n",
    "Consolidate the given data.\n",
    "\n",
    "Each item in the given list is an income statement for a given year.\n",
    "\n",
    "The keys need to be consolidated across the years.\n",
    "\n",
    "You may leave some keys as None if there is no matching data for a given year.\n",
    "However, try your best to leave as little data gaps as possible. If there is a\n",
    "reported figure for a given year, it is likely in all years, or subsequent\n",
    "years. For example, \"assets\" may change to \"total_assets\", but these should be\n",
    "merged. There should be no nesting of dictionaries; the data for a given year\n",
    "should be numbers.\n",
    "\n",
    "Use your knowledge about the common items occurring in an income statement.\n",
    "\n",
    "Your output should be json.loads ready.\n",
    "\n",
    "Special instructions:\n",
    "{special_instructions}\n",
    "\n",
    "Data:\n",
    "{income_statement}\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o3-mini\",\n",
    "    input=instruction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(json.loads(response.output_text)).set_index('year').to_csv(f\"{root_path}\\\\income_statement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_instructions = \"Prefer VW group data over automotive group data.\"\n",
    "\n",
    "instruction = f\"\"\"\n",
    "Consolidate the given data.\n",
    "\n",
    "Each item in the given list is a cash flow statement for a given year.\n",
    "\n",
    "The keys need to be consolidated across the years.\n",
    "\n",
    "You may leave some keys as None if there is no matching data for a given year.\n",
    "However, try your best to leave as little data gaps as possible. If there is a\n",
    "reported figure for a given year, it is likely in all years, or subsequent\n",
    "years. For example, \"assets\" may change to \"total_assets\", but these should be\n",
    "merged. There should be no nesting of dictionaries; the data for a given year\n",
    "should be numbers.\n",
    "\n",
    "Use your knowledge about the common items occurring in a cash flow statement.\n",
    "\n",
    "Your output should be json.loads ready.\n",
    "\n",
    "Special instructions:\n",
    "{special_instructions}\n",
    "\n",
    "Data:\n",
    "{cash_flow_statement}\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o3-mini\",\n",
    "    input=instruction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(json.loads(response.output_text)).set_index('year').to_csv(f\"{root_path}\\\\cash_flow_statement.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance_sheet = pd.read_csv(f\"{root_path}\\\\balance_sheet.csv\", index_col=0)\n",
    "df_income_statement = pd.read_csv(f\"{root_path}\\\\income_statement.csv\", index_col=0)\n",
    "df_cash_flow_statement = pd.read_csv(f\"{root_path}\\\\cash_flow_statement.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance_sheet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "df_balance_sheet['total_assets'].plot(label='Total Assets', ax=ax[0])\n",
    "df_balance_sheet['current_assets'].plot(label='Current Assets', ax=ax[0])\n",
    "df_balance_sheet['noncurrent_assets'].plot(label='Non-Current Assets', ax=ax[0])\n",
    "df_balance_sheet[['current_liabilities', 'noncurrent_liabilities']].dropna().sum(axis=1).plot(label='Total Liabilities', ax=ax[1])\n",
    "df_balance_sheet['current_liabilities'].dropna().plot(label='Current Liabilities', ax=ax[1])\n",
    "df_balance_sheet['noncurrent_liabilities'].dropna().plot(label='Non-Current Liabilities', ax=ax[1])\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "fig.suptitle('Balance Sheet Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income_statement.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income_statement['gross_profit'].plot(label='Gross Profit', title='Income Statement')\n",
    "df_income_statement['sales_revenue'].plot(label='Total Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cash Flow Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cash_flow_statement.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cash_flow_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cash_flow_statement['cash_and_cash_equivalents_at_beginning_of_period'].dropna().plot()\n",
    "df_cash_flow_statement['cash_and_cash_equivalents_at_end_of_period'].dropna().plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
